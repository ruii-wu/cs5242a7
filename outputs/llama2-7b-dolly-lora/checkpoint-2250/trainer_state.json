{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.9980013324450367,
  "eval_steps": 150,
  "global_step": 2250,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0013324450366422385,
      "grad_norm": 0.3736497759819031,
      "learning_rate": 2.9411764705882355e-06,
      "loss": 1.9009,
      "step": 1
    },
    {
      "epoch": 0.013324450366422385,
      "grad_norm": 0.2698391079902649,
      "learning_rate": 2.9411764705882354e-05,
      "loss": 1.8362,
      "step": 10
    },
    {
      "epoch": 0.02664890073284477,
      "grad_norm": 0.33174026012420654,
      "learning_rate": 5.882352941176471e-05,
      "loss": 1.8892,
      "step": 20
    },
    {
      "epoch": 0.039973351099267154,
      "grad_norm": 0.511859118938446,
      "learning_rate": 8.823529411764706e-05,
      "loss": 1.7322,
      "step": 30
    },
    {
      "epoch": 0.05329780146568954,
      "grad_norm": 0.39517971873283386,
      "learning_rate": 0.00011764705882352942,
      "loss": 1.4795,
      "step": 40
    },
    {
      "epoch": 0.06662225183211193,
      "grad_norm": 0.28623127937316895,
      "learning_rate": 0.00014705882352941178,
      "loss": 1.3339,
      "step": 50
    },
    {
      "epoch": 0.07994670219853431,
      "grad_norm": 0.3446465730667114,
      "learning_rate": 0.00017647058823529413,
      "loss": 1.292,
      "step": 60
    },
    {
      "epoch": 0.09327115256495669,
      "grad_norm": 0.3349725604057312,
      "learning_rate": 0.00019999958540892524,
      "loss": 1.3856,
      "step": 70
    },
    {
      "epoch": 0.10659560293137908,
      "grad_norm": 0.22765451669692993,
      "learning_rate": 0.00019998507508226524,
      "loss": 1.4249,
      "step": 80
    },
    {
      "epoch": 0.11992005329780146,
      "grad_norm": 0.3356986343860626,
      "learning_rate": 0.00019994983863945388,
      "loss": 1.3129,
      "step": 90
    },
    {
      "epoch": 0.13324450366422386,
      "grad_norm": 0.25085777044296265,
      "learning_rate": 0.0001998938833847273,
      "loss": 1.305,
      "step": 100
    },
    {
      "epoch": 0.14656895403064624,
      "grad_norm": 0.32990437746047974,
      "learning_rate": 0.00019981722091716783,
      "loss": 1.2846,
      "step": 110
    },
    {
      "epoch": 0.15989340439706862,
      "grad_norm": 0.29666420817375183,
      "learning_rate": 0.00019971986712829932,
      "loss": 1.3034,
      "step": 120
    },
    {
      "epoch": 0.173217854763491,
      "grad_norm": 0.2848030924797058,
      "learning_rate": 0.00019960184219879303,
      "loss": 1.2739,
      "step": 130
    },
    {
      "epoch": 0.18654230512991338,
      "grad_norm": 0.36084744334220886,
      "learning_rate": 0.00019946317059428448,
      "loss": 1.2977,
      "step": 140
    },
    {
      "epoch": 0.19986675549633579,
      "grad_norm": 0.3396812379360199,
      "learning_rate": 0.00019930388106030166,
      "loss": 1.3096,
      "step": 150
    },
    {
      "epoch": 0.19986675549633579,
      "eval_loss": 1.3133912086486816,
      "eval_runtime": 53.4596,
      "eval_samples_per_second": 28.077,
      "eval_steps_per_second": 14.048,
      "step": 150
    },
    {
      "epoch": 0.21319120586275817,
      "grad_norm": 0.34624889492988586,
      "learning_rate": 0.00019912400661630658,
      "loss": 1.3185,
      "step": 160
    },
    {
      "epoch": 0.22651565622918055,
      "grad_norm": 0.28681480884552,
      "learning_rate": 0.00019892358454885042,
      "loss": 1.3201,
      "step": 170
    },
    {
      "epoch": 0.23984010659560293,
      "grad_norm": 0.3614758253097534,
      "learning_rate": 0.00019870265640384435,
      "loss": 1.3875,
      "step": 180
    },
    {
      "epoch": 0.25316455696202533,
      "grad_norm": 0.353013277053833,
      "learning_rate": 0.00019846126797794743,
      "loss": 1.3016,
      "step": 190
    },
    {
      "epoch": 0.2664890073284477,
      "grad_norm": 0.2295919954776764,
      "learning_rate": 0.00019819946930907332,
      "loss": 1.2299,
      "step": 200
    },
    {
      "epoch": 0.2798134576948701,
      "grad_norm": 0.3233760595321655,
      "learning_rate": 0.00019791731466601773,
      "loss": 1.2823,
      "step": 210
    },
    {
      "epoch": 0.2931379080612925,
      "grad_norm": 0.3267171382904053,
      "learning_rate": 0.00019761486253720915,
      "loss": 1.3552,
      "step": 220
    },
    {
      "epoch": 0.30646235842771485,
      "grad_norm": 0.4609455168247223,
      "learning_rate": 0.00019729217561858433,
      "loss": 1.3734,
      "step": 230
    },
    {
      "epoch": 0.31978680879413723,
      "grad_norm": 0.24998623132705688,
      "learning_rate": 0.00019694932080059217,
      "loss": 1.2939,
      "step": 240
    },
    {
      "epoch": 0.3331112591605596,
      "grad_norm": 0.27043378353118896,
      "learning_rate": 0.00019658636915432788,
      "loss": 1.2767,
      "step": 250
    },
    {
      "epoch": 0.346435709526982,
      "grad_norm": 0.2459440976381302,
      "learning_rate": 0.00019620339591680023,
      "loss": 1.292,
      "step": 260
    },
    {
      "epoch": 0.3597601598934044,
      "grad_norm": 0.307168573141098,
      "learning_rate": 0.00019580048047533578,
      "loss": 1.2759,
      "step": 270
    },
    {
      "epoch": 0.37308461025982675,
      "grad_norm": 0.22862257063388824,
      "learning_rate": 0.0001953777063511223,
      "loss": 1.2775,
      "step": 280
    },
    {
      "epoch": 0.3864090606262492,
      "grad_norm": 0.26822465658187866,
      "learning_rate": 0.00019493516118189582,
      "loss": 1.3231,
      "step": 290
    },
    {
      "epoch": 0.39973351099267157,
      "grad_norm": 0.3080412745475769,
      "learning_rate": 0.0001944729367037736,
      "loss": 1.2332,
      "step": 300
    },
    {
      "epoch": 0.39973351099267157,
      "eval_loss": 1.2981733083724976,
      "eval_runtime": 53.2199,
      "eval_samples_per_second": 28.204,
      "eval_steps_per_second": 14.111,
      "step": 300
    },
    {
      "epoch": 0.41305796135909395,
      "grad_norm": 0.24777142703533173,
      "learning_rate": 0.00019399112873223824,
      "loss": 1.3114,
      "step": 310
    },
    {
      "epoch": 0.42638241172551633,
      "grad_norm": 0.29816383123397827,
      "learning_rate": 0.00019348983714227583,
      "loss": 1.2829,
      "step": 320
    },
    {
      "epoch": 0.4397068620919387,
      "grad_norm": 0.26467248797416687,
      "learning_rate": 0.00019296916584767262,
      "loss": 1.3612,
      "step": 330
    },
    {
      "epoch": 0.4530313124583611,
      "grad_norm": 0.33116111159324646,
      "learning_rate": 0.00019242922277947448,
      "loss": 1.2636,
      "step": 340
    },
    {
      "epoch": 0.46635576282478347,
      "grad_norm": 0.26759105920791626,
      "learning_rate": 0.00019187011986361374,
      "loss": 1.279,
      "step": 350
    },
    {
      "epoch": 0.47968021319120585,
      "grad_norm": 0.2789662480354309,
      "learning_rate": 0.0001912919729977078,
      "loss": 1.297,
      "step": 360
    },
    {
      "epoch": 0.49300466355762823,
      "grad_norm": 0.2138008177280426,
      "learning_rate": 0.00019069490202703438,
      "loss": 1.3088,
      "step": 370
    },
    {
      "epoch": 0.5063291139240507,
      "grad_norm": 0.3054181933403015,
      "learning_rate": 0.00019007903071968868,
      "loss": 1.274,
      "step": 380
    },
    {
      "epoch": 0.519653564290473,
      "grad_norm": 0.27655693888664246,
      "learning_rate": 0.00018944448674092714,
      "loss": 1.2206,
      "step": 390
    },
    {
      "epoch": 0.5329780146568954,
      "grad_norm": 0.28153857588768005,
      "learning_rate": 0.00018879140162670347,
      "loss": 1.3154,
      "step": 400
    },
    {
      "epoch": 0.5463024650233178,
      "grad_norm": 0.24049919843673706,
      "learning_rate": 0.00018811991075640223,
      "loss": 1.294,
      "step": 410
    },
    {
      "epoch": 0.5596269153897402,
      "grad_norm": 0.20796991884708405,
      "learning_rate": 0.00018743015332477588,
      "loss": 1.3829,
      "step": 420
    },
    {
      "epoch": 0.5729513657561626,
      "grad_norm": 0.24016542732715607,
      "learning_rate": 0.00018672227231309068,
      "loss": 1.2475,
      "step": 430
    },
    {
      "epoch": 0.586275816122585,
      "grad_norm": 0.23849263787269592,
      "learning_rate": 0.0001859964144594879,
      "loss": 1.3198,
      "step": 440
    },
    {
      "epoch": 0.5996002664890073,
      "grad_norm": 0.19535449147224426,
      "learning_rate": 0.00018525273022856607,
      "loss": 1.2874,
      "step": 450
    },
    {
      "epoch": 0.5996002664890073,
      "eval_loss": 1.290724515914917,
      "eval_runtime": 53.47,
      "eval_samples_per_second": 28.072,
      "eval_steps_per_second": 14.045,
      "step": 450
    },
    {
      "epoch": 0.6129247168554297,
      "grad_norm": 0.23061633110046387,
      "learning_rate": 0.00018449137378019094,
      "loss": 1.3517,
      "step": 460
    },
    {
      "epoch": 0.6262491672218521,
      "grad_norm": 0.26931363344192505,
      "learning_rate": 0.0001837125029375393,
      "loss": 1.2978,
      "step": 470
    },
    {
      "epoch": 0.6395736175882745,
      "grad_norm": 0.3323110044002533,
      "learning_rate": 0.00018291627915438348,
      "loss": 1.269,
      "step": 480
    },
    {
      "epoch": 0.6528980679546968,
      "grad_norm": 0.2656368315219879,
      "learning_rate": 0.00018210286748162336,
      "loss": 1.3049,
      "step": 490
    },
    {
      "epoch": 0.6662225183211192,
      "grad_norm": 0.2844024896621704,
      "learning_rate": 0.00018127243653307248,
      "loss": 1.2921,
      "step": 500
    },
    {
      "epoch": 0.6795469686875416,
      "grad_norm": 0.21106350421905518,
      "learning_rate": 0.00018042515845050576,
      "loss": 1.2923,
      "step": 510
    },
    {
      "epoch": 0.692871419053964,
      "grad_norm": 0.3201788067817688,
      "learning_rate": 0.00017956120886797604,
      "loss": 1.2941,
      "step": 520
    },
    {
      "epoch": 0.7061958694203864,
      "grad_norm": 0.297830730676651,
      "learning_rate": 0.00017868076687540624,
      "loss": 1.3278,
      "step": 530
    },
    {
      "epoch": 0.7195203197868087,
      "grad_norm": 0.18231120705604553,
      "learning_rate": 0.0001777840149814657,
      "loss": 1.3174,
      "step": 540
    },
    {
      "epoch": 0.7328447701532311,
      "grad_norm": 0.1994747370481491,
      "learning_rate": 0.0001768711390757374,
      "loss": 1.2638,
      "step": 550
    },
    {
      "epoch": 0.7461692205196535,
      "grad_norm": 0.28554338216781616,
      "learning_rate": 0.0001759423283901846,
      "loss": 1.2935,
      "step": 560
    },
    {
      "epoch": 0.759493670886076,
      "grad_norm": 0.2471923679113388,
      "learning_rate": 0.00017499777545992452,
      "loss": 1.2613,
      "step": 570
    },
    {
      "epoch": 0.7728181212524984,
      "grad_norm": 0.21638807654380798,
      "learning_rate": 0.00017403767608331733,
      "loss": 1.3115,
      "step": 580
    },
    {
      "epoch": 0.7861425716189208,
      "grad_norm": 0.3231382369995117,
      "learning_rate": 0.00017306222928137875,
      "loss": 1.258,
      "step": 590
    },
    {
      "epoch": 0.7994670219853431,
      "grad_norm": 0.2514064610004425,
      "learning_rate": 0.00017207163725652445,
      "loss": 1.2001,
      "step": 600
    },
    {
      "epoch": 0.7994670219853431,
      "eval_loss": 1.2873375415802002,
      "eval_runtime": 53.4306,
      "eval_samples_per_second": 28.092,
      "eval_steps_per_second": 14.056,
      "step": 600
    },
    {
      "epoch": 0.8127914723517655,
      "grad_norm": 0.22515137493610382,
      "learning_rate": 0.00017106610535065517,
      "loss": 1.2929,
      "step": 610
    },
    {
      "epoch": 0.8261159227181879,
      "grad_norm": 0.20822551846504211,
      "learning_rate": 0.00017004584200259107,
      "loss": 1.2885,
      "step": 620
    },
    {
      "epoch": 0.8394403730846103,
      "grad_norm": 0.36481186747550964,
      "learning_rate": 0.00016901105870486372,
      "loss": 1.3223,
      "step": 630
    },
    {
      "epoch": 0.8527648234510327,
      "grad_norm": 0.22331614792346954,
      "learning_rate": 0.0001679619699598757,
      "loss": 1.3271,
      "step": 640
    },
    {
      "epoch": 0.866089273817455,
      "grad_norm": 0.32357877492904663,
      "learning_rate": 0.00016689879323543566,
      "loss": 1.2759,
      "step": 650
    },
    {
      "epoch": 0.8794137241838774,
      "grad_norm": 0.25324776768684387,
      "learning_rate": 0.0001658217489196792,
      "loss": 1.2611,
      "step": 660
    },
    {
      "epoch": 0.8927381745502998,
      "grad_norm": 0.2143891602754593,
      "learning_rate": 0.00016473106027538393,
      "loss": 1.2661,
      "step": 670
    },
    {
      "epoch": 0.9060626249167222,
      "grad_norm": 0.21308356523513794,
      "learning_rate": 0.00016362695339368913,
      "loss": 1.3074,
      "step": 680
    },
    {
      "epoch": 0.9193870752831446,
      "grad_norm": 0.22966276109218597,
      "learning_rate": 0.0001625096571472285,
      "loss": 1.2677,
      "step": 690
    },
    {
      "epoch": 0.9327115256495669,
      "grad_norm": 0.2396954596042633,
      "learning_rate": 0.00016137940314268695,
      "loss": 1.3191,
      "step": 700
    },
    {
      "epoch": 0.9460359760159893,
      "grad_norm": 0.17582058906555176,
      "learning_rate": 0.00016023642567279033,
      "loss": 1.2699,
      "step": 710
    },
    {
      "epoch": 0.9593604263824117,
      "grad_norm": 0.35956376791000366,
      "learning_rate": 0.00015908096166773817,
      "loss": 1.304,
      "step": 720
    },
    {
      "epoch": 0.9726848767488341,
      "grad_norm": 0.1768663376569748,
      "learning_rate": 0.0001579132506460903,
      "loss": 1.3163,
      "step": 730
    },
    {
      "epoch": 0.9860093271152565,
      "grad_norm": 0.18783748149871826,
      "learning_rate": 0.00015673353466511618,
      "loss": 1.2916,
      "step": 740
    },
    {
      "epoch": 0.9993337774816788,
      "grad_norm": 0.24598194658756256,
      "learning_rate": 0.00015554205827061855,
      "loss": 1.2674,
      "step": 750
    },
    {
      "epoch": 0.9993337774816788,
      "eval_loss": 1.2840381860733032,
      "eval_runtime": 53.308,
      "eval_samples_per_second": 28.157,
      "eval_steps_per_second": 14.088,
      "step": 750
    },
    {
      "epoch": 1.0126582278481013,
      "grad_norm": 0.2532901167869568,
      "learning_rate": 0.0001543390684462409,
      "loss": 1.2943,
      "step": 760
    },
    {
      "epoch": 1.0259826782145236,
      "grad_norm": 0.2587824761867523,
      "learning_rate": 0.00015312481456226986,
      "loss": 1.3173,
      "step": 770
    },
    {
      "epoch": 1.039307128580946,
      "grad_norm": 0.19760210812091827,
      "learning_rate": 0.00015189954832394266,
      "loss": 1.2784,
      "step": 780
    },
    {
      "epoch": 1.0526315789473684,
      "grad_norm": 0.32202792167663574,
      "learning_rate": 0.00015066352371927047,
      "loss": 1.2938,
      "step": 790
    },
    {
      "epoch": 1.0659560293137909,
      "grad_norm": 0.24812179803848267,
      "learning_rate": 0.00014941699696638887,
      "loss": 1.3638,
      "step": 800
    },
    {
      "epoch": 1.0792804796802131,
      "grad_norm": 0.2850598692893982,
      "learning_rate": 0.0001481602264604457,
      "loss": 1.2841,
      "step": 810
    },
    {
      "epoch": 1.0926049300466356,
      "grad_norm": 0.2642822563648224,
      "learning_rate": 0.00014689347272003813,
      "loss": 1.2502,
      "step": 820
    },
    {
      "epoch": 1.1059293804130579,
      "grad_norm": 0.276172012090683,
      "learning_rate": 0.0001456169983332087,
      "loss": 1.3204,
      "step": 830
    },
    {
      "epoch": 1.1192538307794804,
      "grad_norm": 0.3006747364997864,
      "learning_rate": 0.0001443310679030132,
      "loss": 1.1952,
      "step": 840
    },
    {
      "epoch": 1.1325782811459026,
      "grad_norm": 0.2440788894891739,
      "learning_rate": 0.00014303594799267065,
      "loss": 1.2928,
      "step": 850
    },
    {
      "epoch": 1.1459027315123251,
      "grad_norm": 0.3171966075897217,
      "learning_rate": 0.0001417319070703066,
      "loss": 1.2395,
      "step": 860
    },
    {
      "epoch": 1.1592271818787476,
      "grad_norm": 0.3244835436344147,
      "learning_rate": 0.00014041921545330193,
      "loss": 1.307,
      "step": 870
    },
    {
      "epoch": 1.17255163224517,
      "grad_norm": 0.24140067398548126,
      "learning_rate": 0.0001390981452522581,
      "loss": 1.2435,
      "step": 880
    },
    {
      "epoch": 1.1858760826115922,
      "grad_norm": 0.37201789021492004,
      "learning_rate": 0.00013776897031459104,
      "loss": 1.243,
      "step": 890
    },
    {
      "epoch": 1.1992005329780147,
      "grad_norm": 0.29025328159332275,
      "learning_rate": 0.00013643196616776432,
      "loss": 1.3016,
      "step": 900
    },
    {
      "epoch": 1.1992005329780147,
      "eval_loss": 1.2834135293960571,
      "eval_runtime": 53.3683,
      "eval_samples_per_second": 28.125,
      "eval_steps_per_second": 14.072,
      "step": 900
    },
    {
      "epoch": 1.2125249833444371,
      "grad_norm": 0.35417264699935913,
      "learning_rate": 0.00013508740996217493,
      "loss": 1.2528,
      "step": 910
    },
    {
      "epoch": 1.2258494337108594,
      "grad_norm": 0.28800344467163086,
      "learning_rate": 0.00013373558041370178,
      "loss": 1.2685,
      "step": 920
    },
    {
      "epoch": 1.239173884077282,
      "grad_norm": 0.244499072432518,
      "learning_rate": 0.00013237675774593045,
      "loss": 1.1102,
      "step": 930
    },
    {
      "epoch": 1.2524983344437042,
      "grad_norm": 0.33409595489501953,
      "learning_rate": 0.00013101122363206488,
      "loss": 1.3417,
      "step": 940
    },
    {
      "epoch": 1.2658227848101267,
      "grad_norm": 0.23969317972660065,
      "learning_rate": 0.00012963926113653863,
      "loss": 1.2537,
      "step": 950
    },
    {
      "epoch": 1.279147235176549,
      "grad_norm": 0.2131456434726715,
      "learning_rate": 0.0001282611546563382,
      "loss": 1.3068,
      "step": 960
    },
    {
      "epoch": 1.2924716855429714,
      "grad_norm": 0.27387535572052,
      "learning_rate": 0.0001268771898620494,
      "loss": 1.3203,
      "step": 970
    },
    {
      "epoch": 1.3057961359093937,
      "grad_norm": 0.29472893476486206,
      "learning_rate": 0.00012548765363864036,
      "loss": 1.181,
      "step": 980
    },
    {
      "epoch": 1.3191205862758162,
      "grad_norm": 0.27136367559432983,
      "learning_rate": 0.00012409283402599238,
      "loss": 1.2493,
      "step": 990
    },
    {
      "epoch": 1.3324450366422385,
      "grad_norm": 0.30168139934539795,
      "learning_rate": 0.00012269302015919172,
      "loss": 1.3268,
      "step": 1000
    },
    {
      "epoch": 1.345769487008661,
      "grad_norm": 0.29636651277542114,
      "learning_rate": 0.00012128850220859397,
      "loss": 1.2743,
      "step": 1010
    },
    {
      "epoch": 1.3590939373750832,
      "grad_norm": 0.3010798394680023,
      "learning_rate": 0.00011987957131967418,
      "loss": 1.2362,
      "step": 1020
    },
    {
      "epoch": 1.3724183877415057,
      "grad_norm": 0.33221086859703064,
      "learning_rate": 0.00011846651955267463,
      "loss": 1.265,
      "step": 1030
    },
    {
      "epoch": 1.385742838107928,
      "grad_norm": 0.2826361060142517,
      "learning_rate": 0.00011704963982206299,
      "loss": 1.2359,
      "step": 1040
    },
    {
      "epoch": 1.3990672884743505,
      "grad_norm": 0.2562638521194458,
      "learning_rate": 0.00011562922583581375,
      "loss": 1.2337,
      "step": 1050
    },
    {
      "epoch": 1.3990672884743505,
      "eval_loss": 1.2823618650436401,
      "eval_runtime": 53.468,
      "eval_samples_per_second": 28.073,
      "eval_steps_per_second": 14.046,
      "step": 1050
    },
    {
      "epoch": 1.4123917388407727,
      "grad_norm": 0.29024896025657654,
      "learning_rate": 0.00011420557203452444,
      "loss": 1.2753,
      "step": 1060
    },
    {
      "epoch": 1.4257161892071952,
      "grad_norm": 0.24615436792373657,
      "learning_rate": 0.00011277897353038085,
      "loss": 1.2491,
      "step": 1070
    },
    {
      "epoch": 1.4390406395736175,
      "grad_norm": 0.32240864634513855,
      "learning_rate": 0.00011134972604598224,
      "loss": 1.2429,
      "step": 1080
    },
    {
      "epoch": 1.45236508994004,
      "grad_norm": 0.29526832699775696,
      "learning_rate": 0.00010991812585304069,
      "loss": 1.1925,
      "step": 1090
    },
    {
      "epoch": 1.4656895403064625,
      "grad_norm": 0.3051118850708008,
      "learning_rate": 0.00010848446971096606,
      "loss": 1.2296,
      "step": 1100
    },
    {
      "epoch": 1.4790139906728847,
      "grad_norm": 0.31913602352142334,
      "learning_rate": 0.0001070490548053503,
      "loss": 1.2708,
      "step": 1110
    },
    {
      "epoch": 1.492338441039307,
      "grad_norm": 0.3322754502296448,
      "learning_rate": 0.00010561217868636313,
      "loss": 1.285,
      "step": 1120
    },
    {
      "epoch": 1.5056628914057295,
      "grad_norm": 0.3081277310848236,
      "learning_rate": 0.00010417413920707222,
      "loss": 1.2925,
      "step": 1130
    },
    {
      "epoch": 1.518987341772152,
      "grad_norm": 0.3942365050315857,
      "learning_rate": 0.0001027352344617007,
      "loss": 1.1957,
      "step": 1140
    },
    {
      "epoch": 1.5323117921385743,
      "grad_norm": 0.3817465901374817,
      "learning_rate": 0.00010129576272383445,
      "loss": 1.2351,
      "step": 1150
    },
    {
      "epoch": 1.5456362425049965,
      "grad_norm": 0.2918485701084137,
      "learning_rate": 9.985602238459247e-05,
      "loss": 1.266,
      "step": 1160
    },
    {
      "epoch": 1.558960692871419,
      "grad_norm": 0.2843742370605469,
      "learning_rate": 9.841631189077269e-05,
      "loss": 1.2274,
      "step": 1170
    },
    {
      "epoch": 1.5722851432378415,
      "grad_norm": 0.22052715718746185,
      "learning_rate": 9.69769296829864e-05,
      "loss": 1.2011,
      "step": 1180
    },
    {
      "epoch": 1.5856095936042638,
      "grad_norm": 0.28072071075439453,
      "learning_rate": 9.553817413379356e-05,
      "loss": 1.2733,
      "step": 1190
    },
    {
      "epoch": 1.598934043970686,
      "grad_norm": 0.25688090920448303,
      "learning_rate": 9.410034348585298e-05,
      "loss": 1.241,
      "step": 1200
    },
    {
      "epoch": 1.598934043970686,
      "eval_loss": 1.2810826301574707,
      "eval_runtime": 53.214,
      "eval_samples_per_second": 28.207,
      "eval_steps_per_second": 14.113,
      "step": 1200
    },
    {
      "epoch": 1.6122584943371085,
      "grad_norm": 0.3271341323852539,
      "learning_rate": 9.266373579009867e-05,
      "loss": 1.2108,
      "step": 1210
    },
    {
      "epoch": 1.625582944703531,
      "grad_norm": 0.3703237473964691,
      "learning_rate": 9.122864884395633e-05,
      "loss": 1.2561,
      "step": 1220
    },
    {
      "epoch": 1.6389073950699533,
      "grad_norm": 0.253054141998291,
      "learning_rate": 8.979538012961221e-05,
      "loss": 1.3135,
      "step": 1230
    },
    {
      "epoch": 1.6522318454363758,
      "grad_norm": 0.26115307211875916,
      "learning_rate": 8.836422675234754e-05,
      "loss": 1.264,
      "step": 1240
    },
    {
      "epoch": 1.6655562958027983,
      "grad_norm": 0.3035667836666107,
      "learning_rate": 8.69354853789509e-05,
      "loss": 1.2117,
      "step": 1250
    },
    {
      "epoch": 1.6788807461692206,
      "grad_norm": 0.3743002712726593,
      "learning_rate": 8.550945217622146e-05,
      "loss": 1.3017,
      "step": 1260
    },
    {
      "epoch": 1.6922051965356428,
      "grad_norm": 0.28935256600379944,
      "learning_rate": 8.408642274957612e-05,
      "loss": 1.242,
      "step": 1270
    },
    {
      "epoch": 1.7055296469020653,
      "grad_norm": 0.26984235644340515,
      "learning_rate": 8.266669208177252e-05,
      "loss": 1.2085,
      "step": 1280
    },
    {
      "epoch": 1.7188540972684878,
      "grad_norm": 0.3751381039619446,
      "learning_rate": 8.125055447176186e-05,
      "loss": 1.2699,
      "step": 1290
    },
    {
      "epoch": 1.73217854763491,
      "grad_norm": 0.2627929151058197,
      "learning_rate": 7.983830347368276e-05,
      "loss": 1.2611,
      "step": 1300
    },
    {
      "epoch": 1.7455029980013324,
      "grad_norm": 0.3966689109802246,
      "learning_rate": 7.843023183600988e-05,
      "loss": 1.287,
      "step": 1310
    },
    {
      "epoch": 1.7588274483677548,
      "grad_norm": 0.258281409740448,
      "learning_rate": 7.702663144086957e-05,
      "loss": 1.3282,
      "step": 1320
    },
    {
      "epoch": 1.7721518987341773,
      "grad_norm": 0.3117099404335022,
      "learning_rate": 7.562779324353477e-05,
      "loss": 1.3014,
      "step": 1330
    },
    {
      "epoch": 1.7854763491005996,
      "grad_norm": 0.32923585176467896,
      "learning_rate": 7.42340072121126e-05,
      "loss": 1.2539,
      "step": 1340
    },
    {
      "epoch": 1.7988007994670219,
      "grad_norm": 0.25057661533355713,
      "learning_rate": 7.284556226743598e-05,
      "loss": 1.3273,
      "step": 1350
    },
    {
      "epoch": 1.7988007994670219,
      "eval_loss": 1.2789722681045532,
      "eval_runtime": 53.2324,
      "eval_samples_per_second": 28.197,
      "eval_steps_per_second": 14.108,
      "step": 1350
    },
    {
      "epoch": 1.8121252498334444,
      "grad_norm": 0.3256492018699646,
      "learning_rate": 7.146274622317288e-05,
      "loss": 1.2748,
      "step": 1360
    },
    {
      "epoch": 1.8254497001998669,
      "grad_norm": 0.4126582443714142,
      "learning_rate": 7.008584572616448e-05,
      "loss": 1.1945,
      "step": 1370
    },
    {
      "epoch": 1.8387741505662891,
      "grad_norm": 0.28402945399284363,
      "learning_rate": 6.871514619700594e-05,
      "loss": 1.2378,
      "step": 1380
    },
    {
      "epoch": 1.8520986009327114,
      "grad_norm": 0.3010609447956085,
      "learning_rate": 6.73509317708807e-05,
      "loss": 1.3031,
      "step": 1390
    },
    {
      "epoch": 1.8654230512991339,
      "grad_norm": 0.36197665333747864,
      "learning_rate": 6.599348523866155e-05,
      "loss": 1.1945,
      "step": 1400
    },
    {
      "epoch": 1.8787475016655564,
      "grad_norm": 0.34263375401496887,
      "learning_rate": 6.464308798829043e-05,
      "loss": 1.2248,
      "step": 1410
    },
    {
      "epoch": 1.8920719520319786,
      "grad_norm": 0.39078041911125183,
      "learning_rate": 6.33000199464487e-05,
      "loss": 1.2912,
      "step": 1420
    },
    {
      "epoch": 1.905396402398401,
      "grad_norm": 0.31053417921066284,
      "learning_rate": 6.196455952053084e-05,
      "loss": 1.2867,
      "step": 1430
    },
    {
      "epoch": 1.9187208527648234,
      "grad_norm": 0.30208131670951843,
      "learning_rate": 6.063698354093255e-05,
      "loss": 1.2439,
      "step": 1440
    },
    {
      "epoch": 1.932045303131246,
      "grad_norm": 0.2589162290096283,
      "learning_rate": 5.931756720366621e-05,
      "loss": 1.2456,
      "step": 1450
    },
    {
      "epoch": 1.9453697534976682,
      "grad_norm": 0.26446017622947693,
      "learning_rate": 5.800658401331467e-05,
      "loss": 1.2819,
      "step": 1460
    },
    {
      "epoch": 1.9586942038640907,
      "grad_norm": 0.31894171237945557,
      "learning_rate": 5.670430572633607e-05,
      "loss": 1.2715,
      "step": 1470
    },
    {
      "epoch": 1.9720186542305131,
      "grad_norm": 0.3114738166332245,
      "learning_rate": 5.5411002294730996e-05,
      "loss": 1.2656,
      "step": 1480
    },
    {
      "epoch": 1.9853431045969354,
      "grad_norm": 0.3995998799800873,
      "learning_rate": 5.412694181008329e-05,
      "loss": 1.3004,
      "step": 1490
    },
    {
      "epoch": 1.9986675549633577,
      "grad_norm": 0.4443908929824829,
      "learning_rate": 5.285239044798695e-05,
      "loss": 1.2415,
      "step": 1500
    },
    {
      "epoch": 1.9986675549633577,
      "eval_loss": 1.2779501676559448,
      "eval_runtime": 53.3021,
      "eval_samples_per_second": 28.16,
      "eval_steps_per_second": 14.089,
      "step": 1500
    },
    {
      "epoch": 2.01199200532978,
      "grad_norm": 0.22098343074321747,
      "learning_rate": 5.1587612412869954e-05,
      "loss": 1.1731,
      "step": 1510
    },
    {
      "epoch": 2.0253164556962027,
      "grad_norm": 0.29390841722488403,
      "learning_rate": 5.0332869883226817e-05,
      "loss": 1.2433,
      "step": 1520
    },
    {
      "epoch": 2.038640906062625,
      "grad_norm": 0.33344656229019165,
      "learning_rate": 4.9088422957271164e-05,
      "loss": 1.2072,
      "step": 1530
    },
    {
      "epoch": 2.051965356429047,
      "grad_norm": 0.3592137098312378,
      "learning_rate": 4.7854529599019213e-05,
      "loss": 1.2609,
      "step": 1540
    },
    {
      "epoch": 2.0652898067954695,
      "grad_norm": 0.29618263244628906,
      "learning_rate": 4.6631445584815926e-05,
      "loss": 1.2665,
      "step": 1550
    },
    {
      "epoch": 2.078614257161892,
      "grad_norm": 0.2873183786869049,
      "learning_rate": 4.54194244503147e-05,
      "loss": 1.1453,
      "step": 1560
    },
    {
      "epoch": 2.0919387075283145,
      "grad_norm": 0.25868383049964905,
      "learning_rate": 4.4218717437921445e-05,
      "loss": 1.2648,
      "step": 1570
    },
    {
      "epoch": 2.1052631578947367,
      "grad_norm": 0.2922969460487366,
      "learning_rate": 4.302957344471383e-05,
      "loss": 1.2239,
      "step": 1580
    },
    {
      "epoch": 2.1185876082611594,
      "grad_norm": 0.34004753828048706,
      "learning_rate": 4.185223897084709e-05,
      "loss": 1.1404,
      "step": 1590
    },
    {
      "epoch": 2.1319120586275817,
      "grad_norm": 0.28371602296829224,
      "learning_rate": 4.068695806845624e-05,
      "loss": 1.2426,
      "step": 1600
    },
    {
      "epoch": 2.145236508994004,
      "grad_norm": 0.3133494257926941,
      "learning_rate": 3.953397229106636e-05,
      "loss": 1.2667,
      "step": 1610
    },
    {
      "epoch": 2.1585609593604262,
      "grad_norm": 0.3309021592140198,
      "learning_rate": 3.839352064352012e-05,
      "loss": 1.3006,
      "step": 1620
    },
    {
      "epoch": 2.171885409726849,
      "grad_norm": 0.30187052488327026,
      "learning_rate": 3.7265839532434155e-05,
      "loss": 1.2331,
      "step": 1630
    },
    {
      "epoch": 2.1852098600932712,
      "grad_norm": 0.34241315722465515,
      "learning_rate": 3.615116271719378e-05,
      "loss": 1.1252,
      "step": 1640
    },
    {
      "epoch": 2.1985343104596935,
      "grad_norm": 0.3777075707912445,
      "learning_rate": 3.504972126149639e-05,
      "loss": 1.2781,
      "step": 1650
    },
    {
      "epoch": 2.1985343104596935,
      "eval_loss": 1.2794750928878784,
      "eval_runtime": 53.222,
      "eval_samples_per_second": 28.203,
      "eval_steps_per_second": 14.111,
      "step": 1650
    },
    {
      "epoch": 2.2118587608261158,
      "grad_norm": 0.33051303029060364,
      "learning_rate": 3.396174348545413e-05,
      "loss": 1.2364,
      "step": 1660
    },
    {
      "epoch": 2.2251832111925385,
      "grad_norm": 0.3759653568267822,
      "learning_rate": 3.288745491826459e-05,
      "loss": 1.2541,
      "step": 1670
    },
    {
      "epoch": 2.2385076615589607,
      "grad_norm": 0.43921446800231934,
      "learning_rate": 3.182707825146056e-05,
      "loss": 1.288,
      "step": 1680
    },
    {
      "epoch": 2.251832111925383,
      "grad_norm": 0.30270346999168396,
      "learning_rate": 3.078083329274767e-05,
      "loss": 1.1757,
      "step": 1690
    },
    {
      "epoch": 2.2651565622918053,
      "grad_norm": 0.38158032298088074,
      "learning_rate": 2.9748936920440286e-05,
      "loss": 1.2293,
      "step": 1700
    },
    {
      "epoch": 2.278481012658228,
      "grad_norm": 0.3419923186302185,
      "learning_rate": 2.873160303850405e-05,
      "loss": 1.2157,
      "step": 1710
    },
    {
      "epoch": 2.2918054630246503,
      "grad_norm": 0.31733518838882446,
      "learning_rate": 2.7729042532215456e-05,
      "loss": 1.2102,
      "step": 1720
    },
    {
      "epoch": 2.3051299133910725,
      "grad_norm": 0.29171401262283325,
      "learning_rate": 2.6741463224446926e-05,
      "loss": 1.2714,
      "step": 1730
    },
    {
      "epoch": 2.3184543637574953,
      "grad_norm": 0.3243328332901001,
      "learning_rate": 2.576906983258669e-05,
      "loss": 1.2554,
      "step": 1740
    },
    {
      "epoch": 2.3317788141239175,
      "grad_norm": 0.30090025067329407,
      "learning_rate": 2.481206392610278e-05,
      "loss": 1.2216,
      "step": 1750
    },
    {
      "epoch": 2.34510326449034,
      "grad_norm": 0.36684516072273254,
      "learning_rate": 2.3870643884758913e-05,
      "loss": 1.2298,
      "step": 1760
    },
    {
      "epoch": 2.358427714856762,
      "grad_norm": 0.3836541175842285,
      "learning_rate": 2.294500485749218e-05,
      "loss": 1.3033,
      "step": 1770
    },
    {
      "epoch": 2.3717521652231843,
      "grad_norm": 0.28893303871154785,
      "learning_rate": 2.203533872196003e-05,
      "loss": 1.1923,
      "step": 1780
    },
    {
      "epoch": 2.385076615589607,
      "grad_norm": 0.2910732924938202,
      "learning_rate": 2.1141834044765774e-05,
      "loss": 1.2715,
      "step": 1790
    },
    {
      "epoch": 2.3984010659560293,
      "grad_norm": 0.34400227665901184,
      "learning_rate": 2.0264676042370025e-05,
      "loss": 1.2794,
      "step": 1800
    },
    {
      "epoch": 2.3984010659560293,
      "eval_loss": 1.279932975769043,
      "eval_runtime": 53.1865,
      "eval_samples_per_second": 28.221,
      "eval_steps_per_second": 14.12,
      "step": 1800
    },
    {
      "epoch": 2.4117255163224516,
      "grad_norm": 0.29112541675567627,
      "learning_rate": 1.940404654269684e-05,
      "loss": 1.2086,
      "step": 1810
    },
    {
      "epoch": 2.4250499666888743,
      "grad_norm": 0.3040110468864441,
      "learning_rate": 1.8560123947442298e-05,
      "loss": 1.2401,
      "step": 1820
    },
    {
      "epoch": 2.4383744170552966,
      "grad_norm": 0.28606265783309937,
      "learning_rate": 1.7733083195093058e-05,
      "loss": 1.2395,
      "step": 1830
    },
    {
      "epoch": 2.451698867421719,
      "grad_norm": 0.4648191034793854,
      "learning_rate": 1.6923095724663297e-05,
      "loss": 1.258,
      "step": 1840
    },
    {
      "epoch": 2.465023317788141,
      "grad_norm": 0.3661635220050812,
      "learning_rate": 1.6130329440156432e-05,
      "loss": 1.2048,
      "step": 1850
    },
    {
      "epoch": 2.478347768154564,
      "grad_norm": 0.30232641100883484,
      "learning_rate": 1.535494867576016e-05,
      "loss": 1.1895,
      "step": 1860
    },
    {
      "epoch": 2.491672218520986,
      "grad_norm": 0.3270757496356964,
      "learning_rate": 1.4597114161781188e-05,
      "loss": 1.1817,
      "step": 1870
    },
    {
      "epoch": 2.5049966688874084,
      "grad_norm": 0.361379474401474,
      "learning_rate": 1.3856982991327128e-05,
      "loss": 1.2533,
      "step": 1880
    },
    {
      "epoch": 2.5183211192538306,
      "grad_norm": 0.33607423305511475,
      "learning_rate": 1.3134708587742362e-05,
      "loss": 1.2519,
      "step": 1890
    },
    {
      "epoch": 2.5316455696202533,
      "grad_norm": 0.35495084524154663,
      "learning_rate": 1.2430440672804545e-05,
      "loss": 1.2772,
      "step": 1900
    },
    {
      "epoch": 2.5449700199866756,
      "grad_norm": 0.39465904235839844,
      "learning_rate": 1.1744325235688536e-05,
      "loss": 1.2094,
      "step": 1910
    },
    {
      "epoch": 2.558294470353098,
      "grad_norm": 0.3562617897987366,
      "learning_rate": 1.1076504502703867e-05,
      "loss": 1.2568,
      "step": 1920
    },
    {
      "epoch": 2.57161892071952,
      "grad_norm": 0.44630318880081177,
      "learning_rate": 1.042711690781254e-05,
      "loss": 1.1896,
      "step": 1930
    },
    {
      "epoch": 2.584943371085943,
      "grad_norm": 0.3573024868965149,
      "learning_rate": 9.796297063932614e-06,
      "loss": 1.1441,
      "step": 1940
    },
    {
      "epoch": 2.598267821452365,
      "grad_norm": 0.44862163066864014,
      "learning_rate": 9.18417573503404e-06,
      "loss": 1.2529,
      "step": 1950
    },
    {
      "epoch": 2.598267821452365,
      "eval_loss": 1.2797960042953491,
      "eval_runtime": 53.4181,
      "eval_samples_per_second": 28.099,
      "eval_steps_per_second": 14.059,
      "step": 1950
    },
    {
      "epoch": 2.6115922718187874,
      "grad_norm": 0.2857646048069,
      "learning_rate": 8.590879809032349e-06,
      "loss": 1.2685,
      "step": 1960
    },
    {
      "epoch": 2.62491672218521,
      "grad_norm": 0.33203962445259094,
      "learning_rate": 8.016532271485789e-06,
      "loss": 1.2724,
      "step": 1970
    },
    {
      "epoch": 2.6382411725516324,
      "grad_norm": 0.423145592212677,
      "learning_rate": 7.461252180101352e-06,
      "loss": 1.2234,
      "step": 1980
    },
    {
      "epoch": 2.6515656229180546,
      "grad_norm": 0.4087512195110321,
      "learning_rate": 6.92515464005511e-06,
      "loss": 1.1801,
      "step": 1990
    },
    {
      "epoch": 2.664890073284477,
      "grad_norm": 0.34146377444267273,
      "learning_rate": 6.408350780131778e-06,
      "loss": 1.2412,
      "step": 2000
    },
    {
      "epoch": 2.678214523650899,
      "grad_norm": 0.29602834582328796,
      "learning_rate": 5.910947729688598e-06,
      "loss": 1.1508,
      "step": 2010
    },
    {
      "epoch": 2.691538974017322,
      "grad_norm": 0.36015671491622925,
      "learning_rate": 5.433048596448287e-06,
      "loss": 1.226,
      "step": 2020
    },
    {
      "epoch": 2.704863424383744,
      "grad_norm": 0.2965540587902069,
      "learning_rate": 4.97475244512563e-06,
      "loss": 1.2316,
      "step": 2030
    },
    {
      "epoch": 2.7181878747501664,
      "grad_norm": 0.31383016705513,
      "learning_rate": 4.5361542768921015e-06,
      "loss": 1.3152,
      "step": 2040
    },
    {
      "epoch": 2.731512325116589,
      "grad_norm": 0.3568021059036255,
      "learning_rate": 4.117345009682916e-06,
      "loss": 1.217,
      "step": 2050
    },
    {
      "epoch": 2.7448367754830114,
      "grad_norm": 0.3692656457424164,
      "learning_rate": 3.718411459350446e-06,
      "loss": 1.2282,
      "step": 2060
    },
    {
      "epoch": 2.7581612258494337,
      "grad_norm": 0.3317812979221344,
      "learning_rate": 3.3394363216679656e-06,
      "loss": 1.2108,
      "step": 2070
    },
    {
      "epoch": 2.771485676215856,
      "grad_norm": 0.29808568954467773,
      "learning_rate": 2.9804981551875054e-06,
      "loss": 1.1365,
      "step": 2080
    },
    {
      "epoch": 2.7848101265822782,
      "grad_norm": 0.4325365722179413,
      "learning_rate": 2.641671364955256e-06,
      "loss": 1.22,
      "step": 2090
    },
    {
      "epoch": 2.798134576948701,
      "grad_norm": 0.3658357262611389,
      "learning_rate": 2.3230261870879956e-06,
      "loss": 1.1884,
      "step": 2100
    },
    {
      "epoch": 2.798134576948701,
      "eval_loss": 1.2795355319976807,
      "eval_runtime": 53.2168,
      "eval_samples_per_second": 28.205,
      "eval_steps_per_second": 14.112,
      "step": 2100
    },
    {
      "epoch": 2.811459027315123,
      "grad_norm": 0.3433590233325958,
      "learning_rate": 2.0246286742136913e-06,
      "loss": 1.2103,
      "step": 2110
    },
    {
      "epoch": 2.8247834776815455,
      "grad_norm": 0.42997369170188904,
      "learning_rate": 1.7465406817793296e-06,
      "loss": 1.2892,
      "step": 2120
    },
    {
      "epoch": 2.838107928047968,
      "grad_norm": 0.3493262529373169,
      "learning_rate": 1.4888198552287624e-06,
      "loss": 1.2591,
      "step": 2130
    },
    {
      "epoch": 2.8514323784143905,
      "grad_norm": 0.32850828766822815,
      "learning_rate": 1.251519618053265e-06,
      "loss": 1.2457,
      "step": 2140
    },
    {
      "epoch": 2.8647568287808127,
      "grad_norm": 0.38174086809158325,
      "learning_rate": 1.0346891607172614e-06,
      "loss": 1.2469,
      "step": 2150
    },
    {
      "epoch": 2.878081279147235,
      "grad_norm": 0.2514403164386749,
      "learning_rate": 8.383734304615143e-07,
      "loss": 1.2976,
      "step": 2160
    },
    {
      "epoch": 2.8914057295136577,
      "grad_norm": 0.337635338306427,
      "learning_rate": 6.626131219859555e-07,
      "loss": 1.2902,
      "step": 2170
    },
    {
      "epoch": 2.90473017988008,
      "grad_norm": 0.2997725009918213,
      "learning_rate": 5.07444669013979e-07,
      "loss": 1.2023,
      "step": 2180
    },
    {
      "epoch": 2.9180546302465022,
      "grad_norm": 0.3353172838687897,
      "learning_rate": 3.729002367399925e-07,
      "loss": 1.2537,
      "step": 2190
    },
    {
      "epoch": 2.931379080612925,
      "grad_norm": 0.3337567448616028,
      "learning_rate": 2.5900771516188527e-07,
      "loss": 1.2372,
      "step": 2200
    },
    {
      "epoch": 2.9447035309793472,
      "grad_norm": 0.3302903175354004,
      "learning_rate": 1.6579071329957395e-07,
      "loss": 1.2689,
      "step": 2210
    },
    {
      "epoch": 2.9580279813457695,
      "grad_norm": 0.48160475492477417,
      "learning_rate": 9.326855430110692e-08,
      "loss": 1.212,
      "step": 2220
    },
    {
      "epoch": 2.9713524317121918,
      "grad_norm": 0.28606975078582764,
      "learning_rate": 4.14562714371014e-08,
      "loss": 1.2183,
      "step": 2230
    },
    {
      "epoch": 2.984676882078614,
      "grad_norm": 0.4413061738014221,
      "learning_rate": 1.036460498445857e-08,
      "loss": 1.2198,
      "step": 2240
    },
    {
      "epoch": 2.9980013324450367,
      "grad_norm": 0.37611445784568787,
      "learning_rate": 0.0,
      "loss": 1.2675,
      "step": 2250
    },
    {
      "epoch": 2.9980013324450367,
      "eval_loss": 1.279547929763794,
      "eval_runtime": 53.2044,
      "eval_samples_per_second": 28.212,
      "eval_steps_per_second": 14.115,
      "step": 2250
    }
  ],
  "logging_steps": 10,
  "max_steps": 2250,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 751,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 4.3615212853714944e+17,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
